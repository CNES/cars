{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute DSM step by step\n",
    "\n",
    "This notebook explains how to run step by step DSM computation with CARS, starting from the prepare step output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters\n",
    "\n",
    "Those parameters need to be set before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the cars folder\n",
    "cars_home = \"TODO\"\n",
    "# Path to the directory containing the content.json file of the prepare step output\n",
    "content_dir = \"TODO\"\n",
    "# ROI to process (roi_file = path to a vector file, raster file or roi_bbox=bounding box), as expected by cars_cli\n",
    "# Use one or the other (roi_file will have precedence if not None)\n",
    "roi_file = \"TODO\"  # Put roi_file=None to use roi_bbox\n",
    "roi_bbox = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"] # Use 4 floats value\n",
    "# Path to output dir where to save figures and data\n",
    "output_dir = \"TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trick to override cars version\n",
    "import sys\n",
    "sys.path = [cars_home] + sys.path\n",
    "import os\n",
    "import math\n",
    "os.environ['OTB_APPLICATION_PATH'] = os.path.join(cars_home,'build','lib','otb','applications')+':'+os.environ['OTB_APPLICATION_PATH']\n",
    "###\n",
    "# Silent OTB info logs\n",
    "os.environ['OTB_LOGGER_LEVEL']='WARNING'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LightSource\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from cars import stereo, parameters, configuration_correlator, rasterization, utils, projection, tiling, filtering, constants\n",
    "from bin.cars_cli import parse_roi_file\n",
    "import pandora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to read the content file from the prepare step, and to retrieve the disparity range. Note that disparity range can be changed here for experimentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = parameters.read_preprocessing_content_file(os.path.join(content_dir,'content.json'))\n",
    "disp_min = int(math.floor(conf['preprocessing']['output']['minimum_disparity']))\n",
    "disp_max = int(math.ceil(conf['preprocessing']['output']['maximum_disparity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set up a configuration for pandora, the disparity estimation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_config = configuration_correlator.configure_correlator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Region Of Interest to Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define the region of interest that will be processed by the notebook. For that, use `roi_file` ( a vector or a raster file) or `roi_bbox` (four float array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roi_file is not None:\n",
    "    bounds, stop_now = parse_roi_file(roi_file, stop_now=True)\n",
    "else: \n",
    "    bounds = (roi_bbox, None)\n",
    "print(\"Bounds: {}, EPSG={}\".format(bounds[0], bounds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to compute the corresponding epipolar region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epipolar_region = stereo.transform_terrain_region_to_epipolar(bounds[0], conf, bounds[1], disp_min, disp_max)\n",
    "print(\"Corresponding epipolar region: {} (size: {} x {} pixels)\".format(epipolar_region, epipolar_region[2]-epipolar_region[0], epipolar_region[3]-epipolar_region[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo-rectify images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before rectifying the images, we need to compute the margins needed by the disparity estimation algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = pandora.marge.get_margins(disp_min, disp_max, corr_config)\n",
    "margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the images rectification function. It will return 3 datasets, respectively for the left image, right image and left color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset, right_dataset, left_color_dataset = stereo.epipolar_rectify_images(conf, epipolar_region, margins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display the left and right images with their masks, and see if epipolar geometry is ok with an horizontal red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = 15\n",
    "clip_percent = 5\n",
    "vmin_left = np.percentile(left_dataset.im,clip_percent)\n",
    "vmax_left = np.percentile(left_dataset.im,100-clip_percent)\n",
    "vmin_right = np.percentile(right_dataset.im,clip_percent)\n",
    "vmax_right = np.percentile(right_dataset.im,100-clip_percent)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_size, 1.05 * fig_size / 2), subplot_kw={'aspect': 1})\n",
    "axes[0].set_title(\"Left image\")\n",
    "axes[0].imshow(left_dataset.im, cmap=\"gray\", interpolation='spline36', vmin=vmin_left, vmax=vmax_left)\n",
    "axes[0].imshow(left_dataset.msk.where(left_dataset.msk !=0), cmap='tab10', alpha=0.5)\n",
    "axes[0].axhline(len(left_dataset.row)/2., color='red')\n",
    "axes[1].set_title(\"Right image\")\n",
    "axes[1].imshow(right_dataset[\"im\"], cmap=\"gray\", interpolation='spline36', vmin=vmin_right, vmax=vmax_right)\n",
    "axes[1].imshow(right_dataset.msk.where(right_dataset.msk !=0), cmap='tab10', alpha=0.5)\n",
    "axes[1].axhline(len(right_dataset.row)/2., color='red')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(output_dir,'epipolar_images.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell computes the anaglyph, which we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset, right_dataset_align = xr.align(left_dataset,right_dataset)\n",
    "anaglyph = np.stack((left_dataset.im,right_dataset_align.im, right_dataset_align.im),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next cell we display the color image as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_color_dataset = left_color_dataset.where(left_color_dataset.im != 0)\n",
    "color_min = left_color_dataset.im.quantile(clip_percent/100., dim=[\"row\", \"col\"])\n",
    "color_max = left_color_dataset.im.quantile((100-clip_percent)/100., dim=[\"row\", \"col\"])\n",
    "left_color_rescaled_dataset = (left_color_dataset.im-color_min)/(color_max-color_min)\n",
    "red_id = 0\n",
    "green_id = 0\n",
    "blue_id = 0\n",
    "if len(left_color_rescaled_dataset.band) > 2:\n",
    "    green_id = 1\n",
    "    blue_id = 2\n",
    "red = left_color_rescaled_dataset.values[red_id,:,:]\n",
    "green = left_color_rescaled_dataset.values[green_id,:,:]\n",
    "blue = left_color_rescaled_dataset.values[blue_id,:,:]\n",
    "rgb = np.stack((red,green,blue), axis=-1)\n",
    "rgb = np.clip(rgb,0,1)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(fig_size, 1.05 * fig_size / 2), subplot_kw={'aspect': 1})\n",
    "axes.imshow(rgb, cmap=\"gray\", interpolation='spline36')\n",
    "fig.savefig(os.path.join(output_dir,'left_color_image.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have stereo-rectified images, we can compute the disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = stereo.compute_disparity(left_dataset, right_dataset, corr_config, disp_min, disp_max, verbose = True, use_sec_disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We crop out margins, since we do not need them anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset, tmp = xr.align(left_dataset,disp['ref'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display left image along with estimated disparity map. Disparity map is overlayed with masked input pixels (gray), detected occlusions (red) and detected false matches (orange)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin_anaglyph = np.array([vmin_left, vmin_right, vmin_right])\n",
    "vmax_anaglyph = np.array([vmax_left, vmax_right, vmax_right])\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_size, 1.05 * fig_size / 2), subplot_kw={'aspect': 1})\n",
    "axes[0].set_title(\"Anaglyph\")\n",
    "im0 = axes[0].imshow(np.clip((anaglyph-vmin_anaglyph)/(vmax_anaglyph-vmin_anaglyph),0,1), cmap=\"gray\", interpolation='spline36')\n",
    "fig.colorbar(im0,  ax=axes[0], orientation='horizontal', fraction=0.1)\n",
    "axes[1].set_title(\"Disparity map\")\n",
    "im1 = axes[1].imshow(disp['ref'].disp, cmap=\"viridis\", vmin=disp_min, vmax=disp_max)\n",
    "axes[1].imshow(left_dataset.msk.where(left_dataset.msk !=0), cmap='Set1',alpha=1, vmin=0, vmax=255)\n",
    "# Will display in red\n",
    "axes[1].imshow(disp['ref']['msk_occlusion'].where(disp['ref']['msk_occlusion'] ==0), cmap='Set1', alpha=1, vmin=0, vmax=255)\n",
    "# Will display in yellow (+140), see color map Set1\n",
    "axes[1].imshow(disp['ref']['msk_false_match'].where(disp['ref']['msk_false_match'] ==0)+140, cmap='Set1', alpha=1, vmin=0, vmax=255)\n",
    "fig.colorbar(im1,  ax=axes[1], orientation='horizontal', fraction=0.1)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(output_dir,'disparity_map.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we estimated the disparity, we can triangulate it to get WGS84 3D points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = stereo.triangulate(conf, disp['ref'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rasterize in the UTM local projection. First thing is to determine the UTM zone to use. There is a convenient function for that, which we call on the first point of our points cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_zone = rasterization.get_utm_zone_as_epsg_code(cloud['ref'].x[0,0], cloud['ref'].y[0,0])\n",
    "print(\"UTM zone derived from point cloud: {}\".format(utm_zone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rasterize at 0.5 meters resolution. Small clusters of 3D points which are linked by a distance of 3 (less than 50 points) will be removed from the point cloud. A statistical filter is also applied on the points cloud to remove outliers by looking at the distribution of the mean distances between each point and its k neighbors. The filtered elements mask will be added to the cloud['ref'] dataset. Feel free to change rasterization parameters.\n",
    "\n",
    "Small components filtering parameters description:\n",
    "* on_ground_margin: margin added to the on ground region to not filter points clusters that were incomplete because they were on the edges. Set to 0 here has there is no tiling.\n",
    "* pts_connection_dist: distance to use to consider that two points are connected\n",
    "* nb_pts_threshold: point clusters that have less than this number of points will be filtered\n",
    "* dist_between_clusters: distance to use to consider that two points clusters are far from each other or not. If a small points cluster is near to another one, it won't be filtered. (None = deactivated)\n",
    "* construct_removed_elt_msk: if set to True, the removed points mask will be added to the cloud datasets in input of the simple_rasterization_dataset)\n",
    "* mask_value: value to use to identify the removed points in the mask\n",
    "\n",
    "Statistical filtering parameters description:\n",
    "* k: number of neighbors\n",
    "* stdev_factor: factor to apply in the distance threshold computation\n",
    "* construct_removed_elt_msk: if set to True, the removed points mask will be added to the cloud datasets in input of the simple_rasterization_dataset\n",
    "* mask_value: value to use to identify the removed points in the mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 0.5 # meters\n",
    "radius = 1 # pixels\n",
    "sigma = 0.3 # pixels\n",
    "\n",
    "# filtering params\n",
    "on_ground_margin = 0\n",
    "pts_connection_dist = 3\n",
    "nb_pts_threshold = 50\n",
    "dist_between_clusters = None #None = deactivated\n",
    "construct_removed_elt_msk = True\n",
    "mask_value = 255\n",
    "small_cpn_filter_params = filtering.SmallComponentsFilterParams(on_ground_margin,\n",
    "                                                                pts_connection_dist,\n",
    "                                                                nb_pts_threshold,\n",
    "                                                                dist_between_clusters,\n",
    "                                                                construct_removed_elt_msk,\n",
    "                                                                mask_value)\n",
    "\n",
    "k = 50\n",
    "std_dev_factor = 5\n",
    "construct_removed_elt_msk = True\n",
    "mask_value = 255\n",
    "statistical_filter_params = filtering.StatisticalFilterParams(k, std_dev_factor, construct_removed_elt_msk, mask_value)\n",
    "\n",
    "# project in the correct epsg code referential (ecef if filters are activated, utm_zone otherwise)\n",
    "if small_cpn_filter_params or statistical_filter_params:\n",
    "    projection.points_cloud_conversion_dataset(cloud['ref'], 4978)\n",
    "else:\n",
    "    projection.points_cloud_conversion_dataset(cloud['ref'], utm_zone)\n",
    "\n",
    "# rasterization\n",
    "if small_cpn_filter_params is not None or statistical_filter_params is not None:\n",
    "    raster, filtered_points = rasterization.simple_rasterization_dataset([cloud['ref']], resolution, utm_zone, [left_color_dataset], radius=radius, sigma=sigma,\n",
    "                                                                         small_cpn_filter_params=small_cpn_filter_params, statistical_filter_params=statistical_filter_params,\n",
    "                                                                         dump_filter_cloud=True)\n",
    "else:\n",
    "    raster = rasterization.simple_rasterization_dataset([cloud['ref']], resolution, utm_zone, [left_color_dataset], radius=radius, sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display the rasterized DSM and color image side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LightSource(azdeg=315, altdeg=70)\n",
    "hmin = raster.hgt.min()\n",
    "hmax = raster.hgt.max()\n",
    "red = (raster.img.values[red_id,:,:]-color_min.values[red_id])/(color_max.values[red_id]-color_min.values[red_id])\n",
    "green = (raster.img.values[green_id,:,:]-color_min.values[green_id])/(color_max.values[green_id]-color_min.values[green_id])\n",
    "blue = (raster.img.values[blue_id,:,:]-color_min.values[blue_id])/(color_max.values[blue_id]-color_min.values[blue_id])\n",
    "rgb = np.stack((red,green,blue), axis=-1)\n",
    "rgb = np.clip(rgb,0,1)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_size, 1.05 * fig_size / 2))\n",
    "axes[0].set_title(\"DSM (meters)\")\n",
    "im0 = axes[0].imshow(ls.shade(raster.hgt.values, cmap=plt.cm.terrain, blend_mode='soft', vert_exag=10, dx=resolution, dy=resolution, vmin=hmin, vmax=hmax))\n",
    "axes[0].grid(True)\n",
    "axes[1].set_title(\"Ortho\")\n",
    "axes[1].imshow(rgb, interpolation='nearest')\n",
    "axes[1].grid(True)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(output_dir,'dsm_and_color.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display usefull statistics, such as the standard deviation or number of points in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_percent = 2\n",
    "std_min = np.nanpercentile(raster.hgt_stdev,clip_percent)\n",
    "std_max = np.nanpercentile(raster.hgt_stdev,100-clip_percent)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_size, 1.05 * fig_size / 2))\n",
    "axes[0].set_title(\"Cells standard deviation (meters)\")\n",
    "im0 = axes[0].imshow(raster.hgt_stdev, cmap=\"YlOrRd\", interpolation='nearest', vmin=std_min, vmax=std_max)\n",
    "fig.colorbar(im0,  ax=axes[0], orientation='vertical', fraction=0.1)\n",
    "axes[0].grid(True)\n",
    "axes[1].set_title(\"Cells number of points\")\n",
    "im1 = axes[1].imshow(raster.n_pts.where(raster.n_pts!=0), cmap=\"YlOrRd\", interpolation='nearest')\n",
    "fig.colorbar(im1,  ax=axes[1], orientation='vertical', fraction=0.1)\n",
    "axes[1].grid(True)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(output_dir,'dsm_stdev_and_nb_points.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: this part may be very long to execute in the notebook. In this part we will display the colorized points cloud in 3D. First step is rescale colors and filter nan values in color and cloud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_filtered = cloud['ref'].where(cloud['ref'][constants.POINTS_CLOUD_CORR_MSK] == 255)\n",
    "color_filtered = left_color_dataset.where(cloud['ref'][constants.POINTS_CLOUD_CORR_MSK] == 255)\n",
    "color_filtered = color_filtered.where(cloud['ref'][constants.POINTS_CLOUD_CORR_MSK] == 255)\n",
    "color_filtered = (color_filtered-color_min)/(color_max-color_min)\n",
    "red = color_filtered.im.values[red_id,:,:]\n",
    "red = red[~np.isnan(red)]\n",
    "green = color_filtered.im.values[green_id,:,:]\n",
    "green = green[~np.isnan(green)]\n",
    "blue = color_filtered.im.values[blue_id,:,:]\n",
    "blue = blue[~np.isnan(blue)]\n",
    "rgb = np.stack((red,green,blue), axis=-1)\n",
    "rgb = np.clip(rgb,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the correct scaling for all axis (autoscaling is not good, since the z axis probably spans a lot less meters than the X and Y axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centerx = np.mean(cloud_filtered.x)\n",
    "centery = np.mean(cloud_filtered.y)\n",
    "centerz = np.mean(cloud_filtered.z)\n",
    "widthx = max(abs(np.min(cloud_filtered.x-centerx)),abs(np.max(cloud_filtered.x-centerx)))\n",
    "widthy = max(abs(np.min(cloud_filtered.y-centery)),abs(np.max(cloud_filtered.y-centery)))\n",
    "widthz = max(abs(np.min(cloud_filtered.z-centerz)),abs(np.max(cloud_filtered.z-centerz)))\n",
    "width = max(widthx, widthy, widthz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can draw a 3D colorized scatter plot of the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(cloud_filtered.x, cloud_filtered.y, cloud_filtered.z, c=rgb , marker='o', s=0.01)\n",
    "ax.set_xlim(centerx-width, centerx+width)\n",
    "ax.set_ylim(centery-width, centery+width)\n",
    "ax.set_zlim(centerz-width, centerz+width)\n",
    "fig.savefig(os.path.join(output_dir,'3d_view.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving left, right and left color datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset.to_netcdf(os.path.join(output_dir, \"left_dataset.nc\"))\n",
    "right_dataset.to_netcdf(os.path.join(output_dir, \"right_dataset.nc\"))\n",
    "left_color_dataset.to_netcdf(os.path.join(output_dir, \"left_color_dataset.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving dispariy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp['ref'].to_netcdf(os.path.join(output_dir, \"disparity.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving triangulated cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud['ref'].to_netcdf(os.path.join(output_dir, \"cloud.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving DSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster.to_netcdf(os.path.join(output_dir, \"dsm.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cloud in ply file format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.write_ply(os.path.join(output_dir,\"points.ply\"),cloud['ref'])\n",
    "if small_cpn_filter_params is not None or statistical_filter_params is not None:\n",
    "    utils.write_ply(os.path.join(output_dir,\"filtered_points.ply\"),filtered_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars-python3.7-pandora-1.b",
   "language": "python",
   "name": "cars-python-3.7-pandora-v1.b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
